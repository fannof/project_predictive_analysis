# -*- coding: utf-8 -*-
"""Proyek_1_Predictive_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y-BEOP7kTzRWvHqvCKzXR5fdvNCsnAjp

# Laporan Proyek Machine Learning - Novan Nur Hidayat

## PENERAPAN ANALISIS PREDIKSI UNTUK HARGA RUMAH (STUDI KASUS: SEATTLE, WASHING, USA)

## Data Understanding

Pasar real estate, seperti yang ada di Seattle, Washing, USA, menghadirkan peluang menarik bagi analis data untuk menganalisis dan memprediksi ke mana harga properti bergerak. Prediksi harga properti menjadi semakin penting dan menguntungkan. Harga properti merupakan indikator yang baik dari kondisi pasar secara keseluruhan dan kesehatan ekonomi suatu negara. Mempertimbangkan data yang diberikan, dalam memperdebatkan sejumlah besar catatan penjualan properti yang disimpan dalam format yang tidak diketahui dan dengan masalah kualitas data yang tidak diketahui.
Data yang digunakan dalam proyek ini bersumber dari Kaggle (kaggle datasets download -d samuelcortinhas/house-price-prediction-seattle)
"""

# Commented out IPython magic to ensure Python compatibility.
# import semua library yang dibutuhkan
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor

# meload data
rumah = pd.read_csv('train.csv')
rumah

"""### Variabel-variabel pada House Price Prediction dataset adalah sebagai berikut:

- beds : jumlah kamar tidur di properti.
- baths : Jumlah kamar mandi di properti. Catatan 0,5 sesuai dengan setengah bak mandi yang memiliki wastafel dan toilet tetapi tidak ada bak mandi atau pancuran.
- size : Total luas lantai properti.
- size_units : Unit pengukuran sebelumnya.
- lot_size : Total luas tanah tempat properti berada. Tanah itu milik pemilik rumah.
- lot_size_units : Unit pengukuran sebelumnya.
- zip_code : Kode pos. Ini adalah kode pos yang digunakan di AS.
- price : Harga properti dijual seharga (dolar AS).
"""

# mengecek informasi pada dataset
rumah.info()

# mengecek deskripsi statistik data
rumah.describe()

"""### Exploratory Data Analysis

- Menangani missing value

    Dari hasil output, terlihat bahwa kolom "lot_size" dan "lot_size_units" memiliki nilai yang hilang (NaN) sebanyak 347 data. Dengan menggunakan teknik dropna, sekarang DataFrame baru (rumah_cleaned_rows) tidak mengandung baris dengan nilai yang hilang di kolom "lot_size" dan "lot_size_units".
"""

# menangani misssing value
jumlah_missing_per_kolom = rumah.isnull().sum()

# menampilkan hasil
jumlah_missing_per_kolom

# penghapusan baris yang mengandung nilai yang hilang
rumah = rumah.dropna(subset=['lot_size', 'lot_size_units'])
rumah

"""- Menangani outliers

    Pada kasus ini, akan dideteksi outliers dengan teknik visualisasi data (boxplot). Kemudian, outliers akan ditangani dengan teknik IQR method. setelah ditangani dengan metode IQR method, dataset yang tersisa menjadi 1682 data.
"""

# mendeteksi outliers untuk fitur beds
sns.boxplot(x=rumah['beds'])

# mendeteksi outliers untuk fitur baths
sns.boxplot(x=rumah['baths'])

# mendeteksi outliers untuk fitur size
sns.boxplot(x=rumah['size'])

# untuk membuat batas bawah, Q1 dikurangi dengan 1,5 * IQR. Kemudian, untuk membuat batas atas, tambahkan 1.5 * IQR dengan Q3
Q1 = rumah.quantile(0.25)
Q3 = rumah.quantile(0.75)
IQR=Q3-Q1
rumah=rumah[~((rumah<(Q1-1.5*IQR))|(rumah>(Q3+1.5*IQR))).any(axis=1)]

# cek ukuran dataset setelah outliers didrop
rumah.shape

"""- Univariate analysis

    Selanjutnya, akan dilakukan proses analisis data dengan teknik Univariate EDA. Pertama, lakukan analisis pada fitur numerik.
    Peningkatan harga rumah sebanding dengan penurunan jumlah sampel. Hal ini dapat dilihat jelas dari histogram "price" yang grafiknya mengalami penurunan seiring dengan semakin banyaknya jumlah sampel (sumbu x).
    Semakin tinggi size, jumlah beds, dan jumlah baths dalam rumah, maka semakin mahal pula harga rumah.
"""

# univariate analysis untuk fitur numerik
numerical_features = ['beds', 'baths', 'size', 'lot_size', 'zip_code', 'price']

# melihat histogram masing-masing fiturnya menggunakan kode berikut
rumah.hist(bins=50, figsize=(20,15))
plt.show()

"""- Multivariate analysis

    Selanjutnya, akan dilakukan analisis data pada fitur numerik menggunakan teknik Multivariate EDA menggunakan fungsi pairplot() dan juga akan mengobservasi korelasi antara fitur numerik dengan fitur target menggunakan fungsi corr().
    Pada pola sebaran data grafik pairplot, terlihat fitur "size" memiliki korelasi positif dengan fitur "price". Sedangkan kedua fitur "lot_size" dan "price" tidak memliki korelasi karena tidak membetuk pola.

"""

# mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(rumah, diag_kind = 'kde')

# evaluasi skor korelasi pada data numerik
plt.figure(figsize=(10, 8))
correlation_matrix = rumah.corr().round(2)

# menge-print nilai di dalam kotak menggunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Pada grafik korelasi terlihat bahwa fitur 'beds', 'baths', dan 'size' memiliki skor korelasi yang besar dengan fitur target 'price'. Artinya, fitur 'price' berkorelasi tinggi dengan ketiga fitur tersebut. Sementara itu, fitur 'lot_size' dan 'zip_code' memiliki korelasi yang sangat kecil sehingga fitur tersebut dapat di-drop.

"""

# membuang fitur dengan korelasi yang sangat kecil dan membuang fitur katergori karena variabelnya sama semua
rumah.drop(['lot_size', 'zip_code', 'size_units', 'lot_size_units'], inplace=True, axis=1)
rumah.head()

# mengecek menggunakan fungsi pairplot
sns.pairplot(rumah[['beds','baths','size']], plot_kws={"s": 3});

"""## Data Preparation

- Train-Test-Split

  Proses membagi himpunan data menjadi data pelatihan dan pengujian adalah langkah yang diperlukan sebelum membuat model. Penting untuk memperkuat semua data yang tersedia untuk menilai beberapa generalisasi model ke data baru. Perlu dicatat bahwa setiap transformasi data yang dilakukan juga berfungsi sebagai komponen model. Karena data test set (uji) mentah, semua transformasi harus dilakukan pada data latih.
"""

X = rumah.drop(["price"],axis =1)
y = rumah["price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""- Standarisasi

  Ketika algoritma pembelajaran mesin diterapkan pada data dengan distribusi yang serupa atau menyimpang, mereka berkinerja lebih baik dan menyatu lebih cepat. Proses penskalaan dan standardisasi membantu mengubah data menjadi format yang lebih mudah dipahami oleh algoritma. Standardisasi adalah teknik transformasi yang paling umum digunakan dalam proses pembangunan model. Ini tidak akan mengubah fitur numerik menggunakan encoding. Teknik yang digunakan adalah StandarScaler dari library Scikit-learn.
"""

numerical_features = ['beds','baths','size']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""## Modeling

Model akan dikembangkan dengan 3 algoritma yang berbeda, dan mencari mana yang memiliki performa paling baik.
"""

# menyiapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""1. k-NN

  Langkah yang pertama, model KNN diinisialisasi dengan menentukan jumlah tetangga terdekat (parameter n_neighbors).
"""

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""2. Random Forest

  Model Random Forest diinisialisasi dengan menentukan beberapa hyperparameter.


"""

# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""3. Boosting Algorithm

  Model Boosting (AdaBoostRegressor) diinisialisasi dengan menentukan hyperparameter tertentu. Parameter yang diatur adalah learning_rate dengan nilai 0.05. random_state digunakan untuk memastikan reproduktibilitas hasil.

"""

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""## Evaluation

- Metrik yang digunakan adalah MSE

  Mean Squared Error (MSE) adalah salah satu metrik evaluasi yang umum digunakan dalam regresi untuk mengukur sejauh mana perbedaan antara nilai prediksi model dengan nilai aktual (ground truth). MSE dihitung dengan menjumlahkan kuadrat selisih antara setiap nilai prediksi dan nilai aktual, kemudian diambil rata-rata dari seluruh data. Nilai MSE semakin kecil semakin baik. Nilai MSE sama dengan nol berarti model memberikan prediksi yang sempurna sesuai dengan nilai aktual.
"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)